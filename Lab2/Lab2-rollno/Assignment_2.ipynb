{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GW18MExyoByK"
      },
      "source": [
        "## <font color=red> You should not import any new libraries. Your code should run with python=3.x</font>\n",
        "## <font color=red> Please don't rename this .ipynb file.</font><br>\n",
        "- Your solutions will be auto-graded. Hence we request you to follow the instructions.\n",
        "- Modify the code only between \n",
        "```\n",
        "## TODO\n",
        "## END TODO\n",
        "```\n",
        "- In addition to above changes, you can play with arguments to the functions for generating plots\n",
        "- We will run the auto grading scripts with private test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCSR1aBfmVPu"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from scipy import linalg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7zKGgQgoPnA"
      },
      "source": [
        "## Please make sure that your code works with loading data from relative path only\n",
        "\n",
        "i.e. ```pd.read_csv('./data/multi_var_lasso.csv')``` should not throw an error when we run the auto-grading scripts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU2CdrwCoQQv"
      },
      "source": [
        "data_multi = pd.read_csv('./data/multi_var_lasso.csv')\n",
        "cols = [f\"x_gt_{idx}\" for idx in range(1, 6)]\n",
        "X_multi = np.array(data_multi[cols])\n",
        "Y_multi = np.array(data_multi['y_gt'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_YZg7Z7g3fl"
      },
      "source": [
        "data_multi_class = pd.read_csv('./data/3_class_perceptron.csv')\n",
        "cols = [f\"x_gt_{idx}\" for idx in range(1, 3)]\n",
        "X_multi_class = np.array(data_multi_class[cols])\n",
        "Y_multi_class = np.array(data_multi_class['y_gt'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DaZIrqza4oc"
      },
      "source": [
        "def mse_multi_var(X, Y, w, b):\n",
        "    '''\n",
        "    Compute mean squared error between predictions and true y values\n",
        "\n",
        "    Args:\n",
        "    X - numpy array of shape (n_samples, 1)\n",
        "    Y - numpy array of shape (n_samples, 1)\n",
        "    w - a float\n",
        "    b - a float\n",
        "    '''\n",
        "\n",
        "    ## TODO\n",
        "\n",
        "    ## END TODO\n",
        "\n",
        "    return mse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6AFlQQWoxSh"
      },
      "source": [
        "def mse_regularized(X, Y, w, b, lamda):\n",
        "    '''\n",
        "    Compute mean squared error between predictions and true y values\n",
        "\n",
        "    Args:\n",
        "    X - numpy array of shape (n_samples, 1)\n",
        "    Y - numpy array of shape (n_samples, 1)\n",
        "    w - a float\n",
        "    b - a float\n",
        "    '''\n",
        "    ## TODO\n",
        "\n",
        "    ## END TODO\n",
        "\n",
        "    return mse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyT4gundogZ5"
      },
      "source": [
        "## Plot Graphs\n",
        "\n",
        "- This function plots the ground truth curve in <font color=green>green</font> and the predicted function in <font color=red>red</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weGoGCzJodzM"
      },
      "source": [
        "def plot_curves(w, b, x, y):\n",
        "  x_gt = np.linspace(-1, 2, 50)\n",
        "  y_gt = 1 - 3 * x_gt - 2 * x_gt ** 2 + 2.5 * x_gt ** 3\n",
        "  # print(x_gt.shape,y_gt.shape)\n",
        "  if len(w) == 1:\n",
        "    y_fit = w * x_gt + b\n",
        "  elif len(w) == 5:\n",
        "    x_fit = x_gt\n",
        "    for pow in range(2, 4):\n",
        "      x_fit = np.vstack([x_fit, np.power(x_gt, pow)])\n",
        "\n",
        "    x_fit = np.vstack([x_fit, np.power(x_gt, 2)])\n",
        "    x_fit = np.vstack([x_fit, np.power(x_gt, 1)])\n",
        "    \n",
        "    y_fit = np.dot(w, x_fit) + b\n",
        "  else:\n",
        "    assert False, 'Pass a valid w'\n",
        "  plt.plot(x_gt, y_gt, color=\"green\", label='1 - 3 * x - 2 * x ** 2 + 2.5 * x ** 3')\n",
        "  plt.plot(x_gt, y_fit, color='red', label=\"Fitted Function y = w.Tx + b\")\n",
        "  if len(x.shape) == 1:\n",
        "    x_plot = np.vstack([x, np.ones(len(x))]).T\n",
        "    # print (x_plot.shape, y.shape)\n",
        "  else:\n",
        "    x_plot = x\n",
        "  plt.scatter(x_plot[:,0],y)\n",
        "  plt.legend()\n",
        "  plt.title(\"Ground Truth Function\")\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oAg-WHfo_j-"
      },
      "source": [
        "def split_data(X, Y, train_ratio=0.6):\n",
        "    '''\n",
        "    Split data into train and validation sets\n",
        "    The first floor(train_ratio*n_sample) samples form the train set\n",
        "    and the remaining the test set\n",
        "\n",
        "    Args:\n",
        "    X - numpy array of shape (n_samples, n_features)\n",
        "    Y - numpy array of shape (n_samples, 1)\n",
        "    train_ratio - fraction of samples to be used as training data\n",
        "\n",
        "    Returns:\n",
        "    X_train, Y_train, X_val, Y_val\n",
        "    '''\n",
        "    ## TODO\n",
        "    \n",
        "    ## END TODO\n",
        "\n",
        "    return X_train, Y_train, X_val, Y_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jF5le-PSpHyI"
      },
      "source": [
        "# Lasso Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXHA6LqRpJOL"
      },
      "source": [
        "X_train, Y_train, X_val, Y_val = split_data(X_multi, Y_multi, train_ratio=0.6)\n",
        "\n",
        "def ista(X_train, Y_train, X_val, Y_val, epochs=100, lr=1e-3, lamda = 1):\n",
        "    '''\n",
        "    Perform multi variable lasso regression using ISTA\n",
        "\n",
        "    Args:\n",
        "    X_train - numpy array of shape (n_samples_train, 5)\n",
        "    Y_train - numpy array of shape (n_samples_train, 1)\n",
        "    X_val - numpy array of shape (n_samples_val, 5)\n",
        "    Y_val - numpy array of shape (n_samples_val, 1)\n",
        "    epochs - number of gradient descent steps\n",
        "    lr - learnig rate\n",
        "    lamda - regularization_weight\n",
        "    '''\n",
        "\n",
        "    w = np.zeros(X_train.shape[1]) #np.random.randn(X_train.shape[1])\n",
        "    b = 0\n",
        "    ## TODO\n",
        "\n",
        "    ## END TODO\n",
        "    \n",
        "    mse_train = mse_regularized(X_train, Y_train, w, b, lamda)\n",
        "    mse_val = mse_regularized(X_val, Y_val, w, b, lamda)\n",
        "    print(f'Validation loss if {mse_val}')\n",
        "    print(f'Training Loss loss if {mse_train}')\n",
        "    print(w.shape,b,X_train.shape,Y_train.shape)\n",
        "    plot_curves(list(w), b, X_train, Y_train)\n",
        "    return w, b\n",
        "\n",
        "ista(X_train, Y_train, X_val, Y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tquhPbDFVo5J"
      },
      "source": [
        "# Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBD7ZLePVhFz"
      },
      "source": [
        "def multivar_reg_closedform(X_train, Y_train, X_val, Y_val, lamda=0.5):\n",
        "\n",
        "    '''\n",
        "    Perform L2 regularized multi variable least squares regression using \n",
        "    closed form update rules\n",
        "\n",
        "    Args:\n",
        "    X_train - numpy array of shape (n_samples_train, 5)\n",
        "    Y_train - numpy array of shape (n_samples_train, 1)\n",
        "    X_val - numpy array of shape (n_samples_val, 5)\n",
        "    Y_val - numpy array of shape (n_samples_val, 1)\n",
        "    lambda - regularization weight\n",
        "    '''\n",
        "\n",
        "    w = np.zeros(X_train.shape[1])\n",
        "    b = 0\n",
        "\n",
        "    ## TODO     #use closed-form solution from previous assignment\n",
        "\n",
        "\n",
        "\n",
        "    ## END TODO\n",
        "\n",
        "    mse_train = mse_multi_var(X_train, Y_train, w, b)\n",
        "    mse_val = mse_multi_var(X_val, Y_val, w, b)\n",
        "    print(f'Validation loss if {mse_val}')\n",
        "    print(f'Training Loss loss if {mse_train}')\n",
        "    plot_curves(list(w), b, X_train, Y_train)\n",
        "    \n",
        "    return w, b\n",
        "\n",
        "multivar_reg_closedform(X_train, Y_train, X_val, Y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HafXtfE0Zx6D"
      },
      "source": [
        "# Bias-Variance Tradeoff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBatCgQgeZi8"
      },
      "source": [
        "#\n",
        "def ridge(X_train, Y_train, X_test,epochs=20, lr=2e-1, lamda = 1):\n",
        "\n",
        "    w = 0.6\n",
        "    b = 2\n",
        "    n = float(len(X_train)) # Number of elements in X\n",
        "\n",
        "    # Performing Gradient Descent \n",
        "\n",
        "    ## TODO\n",
        "\n",
        "    ### END TODO\n",
        "\n",
        "    Y_pred = w*X_test+b\n",
        "    return Y_pred\n",
        "\n",
        "def lasso(X_train, Y_train, X_test,epochs=20, lr=2e-1, lamda = 1):\n",
        "    w = 0.6\n",
        "    b = 2\n",
        "    n = float(len(X_train)) # Number of elements in X\n",
        "\n",
        "    # Performing Gradient Descent \n",
        "    ##TODO\n",
        "\n",
        "    ##END TODO\n",
        "\n",
        "    Y_pred = w*X_test+b\n",
        "    return Y_pred\n",
        "\n",
        "def ols(X_train, Y_train, X_test,epochs=20, lr=2e-1):\n",
        "\n",
        "    w = 0.6\n",
        "    b = 2\n",
        "    n = float(len(X_train)) # Number of elements in X\n",
        "\n",
        "    # Performing Gradient Descent \n",
        "    ## TODO\n",
        "\n",
        "    ### END TODO\n",
        "\n",
        "    Y_pred = w*X_test+b\n",
        "    return Y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78u8LgPFZxZ0"
      },
      "source": [
        "# We fit multiple lines onto our linear model defined by y = c + mx + error.\n",
        "num_lines = 10\n",
        "#size of Dataset, len(Dataset) for 1 line\n",
        "n = 500\n",
        "#weights (slope/intercept)\n",
        "c = 3\n",
        "m = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjwhG142Z6pL"
      },
      "source": [
        "def gen_data():\n",
        "    '''\n",
        "    We sample n, X from uniform distribution and error from zero mean normal distribtion, we find Y using mx+c+e\n",
        "    We do the above for num_lines number of time, to fit different lines for each models(lasso, ols, ridge), doing so will\n",
        "    be helpfull in calculating Expected value of learned esitmator of all n*num_lines dataset\n",
        "\n",
        "    DO NOT CHANGE this function.\n",
        "    '''\n",
        "\n",
        "    w0 = c\n",
        "    w1 = m\n",
        "    data = np.zeros(shape=(num_lines,n,2))\n",
        "    for i in range(num_lines):\n",
        "        x = np.random.uniform(-2, 2, size=(n, 1))\n",
        "        e = np.random.normal(0, 8, size=(n, 1))\n",
        "        y = w0 + w1 * x + e\n",
        "        x_y = np.concatenate((x, y), axis=1)\n",
        "        data[i,:,:] = x_y\n",
        "    return np.array(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXpyZZMLZ-wk"
      },
      "source": [
        "def gen_bais_variance(Y_preds, Y_true):\n",
        "    ## TODO\n",
        "\n",
        "    ## END TODO\n",
        "    return bias, variance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMzoObAiaBTX"
      },
      "source": [
        "def make_prediction(data, X_test, lambda_=0.5):\n",
        "\n",
        "  y_hat = np.zeros(shape=(num_lines, 3))#store prediction of all model\n",
        "\n",
        "  for i in range(num_lines):\n",
        "      X = data[i, :, 0].reshape(n ,1)\n",
        "      y = data[i, :, 1].reshape(n, 1)\n",
        "\n",
        "      y_hat[i, 0] = ols(X, y, X_test)\n",
        "\n",
        "      y_hat[i, 1] = ridge(X, y, X_test, lamda = lambda_)\n",
        "\n",
        "      y_hat[i, 2] = lasso(X, y, X_test, lamda = lambda_)\n",
        "\n",
        "  return y_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DinGJiTgaENE"
      },
      "source": [
        "def plot_figure(l,b,v):\n",
        "\n",
        "  plt.plot(l, b[:, 0], label=\"OLS\")\n",
        "  plt.plot(l, b[:, 1], label=\"Ridge\")\n",
        "  plt.plot(l, b[:, 2], label=\"Lasso\")\n",
        "  plt.xlabel(\"Regularization coefficient\")\n",
        "  plt.ylabel(\"Bias\")\n",
        "  plt.title(\"Bias vs Lambda\")\n",
        "  plt.legend(loc=\"upper left\")\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(l, v[:, 0], label=\"OLS\")\n",
        "  plt.plot(l, v[:, 1], label=\"Ridge\")\n",
        "  plt.plot(l, v[:, 2], label=\"Lasso\")\n",
        "  plt.xlabel(\"Regularization coefficient\")\n",
        "  plt.ylabel(\"Variance\")\n",
        "  plt.title(\"Variance vs Lambda\")\n",
        "  plt.legend(loc=\"lower left\")\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJD2hCXxaIAA"
      },
      "source": [
        "def driver():\n",
        "  all_lambda = np.linspace(0.0001, 1, 100)\n",
        "  all_bias = np.zeros(shape=(len(all_lambda), 3))\n",
        "  all_variance = np.zeros(shape=(len(all_lambda), 3))\n",
        "  dataset = gen_data()\n",
        "  X_test = np.array([4]).reshape((1,1))\n",
        "  for i, l in enumerate(all_lambda):\n",
        "      Y_hat = make_prediction(dataset, X_test, lambda_=l)\n",
        "      ##TODO #calculate true mean Y_true\n",
        "\n",
        "      ##END TODO\n",
        "      all_bias[i, :], all_variance[i, :] = gen_bais_variance(Y_hat, Y_true) \n",
        "  plot_figure(all_lambda, all_bias, all_variance)\n",
        "\n",
        "driver()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo75okrxU6D0"
      },
      "source": [
        "# Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaL7Zo3nU8Vm"
      },
      "source": [
        "X_train_multiclass, Y_train_multiclass, X_val_multiclass, Y_val_multiclass = split_data(X_multi_class, Y_multi_class, train_ratio=0.6)\n",
        "\n",
        "def perceptron_algo(X_train_multiclass, Y_train_multiclass, X_val_multiclass, Y_val_multiclass,n_class=3, epochs=30):\n",
        "  W=np.zeros((n_class, len(X_train_multiclass[0]) ))\n",
        "  ## TODO\n",
        "\n",
        "  ##END TODO\n",
        "\n",
        "  Y_pred=list()\n",
        "  for i in range(len(Y_val_multiclass)):\n",
        "      y_pred=np.argmax([np.dot(W[0],X_val_multiclass[i]),np.dot(W[1],X_val_multiclass[i]),np.dot(W[2],X_val_multiclass[i])])\n",
        "      Y_pred.append(y_pred)\n",
        "\n",
        "  from sklearn.metrics import classification_report\n",
        "  target_names = ['class 0', 'class 1', 'class 2']\n",
        "  print(classification_report(Y_val_multiclass, Y_pred, target_names=target_names))\n",
        "  return W\n",
        "\n",
        "perceptron_algo(X_train_multiclass, Y_train_multiclass, X_val_multiclass, Y_val_multiclass)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}